{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python2.6  \n",
    "# -*- coding: utf-8 -*-  \n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import math\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #显示中文标签\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/opt/tv/training/training\"\n",
    "valid_dir = \"/opt/tv/validation/validation\"\n",
    "\n",
    "dir1 = os.listdir(train_dir)\n",
    "\n",
    "dir2 = os.listdir(valid_dir)\n",
    "\n",
    "height = 128\n",
    "width = 128\n",
    "channels = 3\n",
    "batch_size = 32\n",
    "num_classes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 893 images belonging to 20 classes.\n",
      "Found 56 images belonging to 20 classes.\n",
      "893\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 20,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    channel_shift_range=10,\n",
    "    brightness_range=[0.1, 1],\n",
    "    fill_mode = 'nearest',\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size = (height, width),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   seed = 7,\n",
    "                                                   shuffle = True,\n",
    "                                                   class_mode = \"categorical\")\n",
    "\n",
    "valid_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_dir,\n",
    "                                                    target_size = (height, width),\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    seed = 7,\n",
    "                                                    shuffle = False,\n",
    "                                                    class_mode = \"categorical\")\n",
    "\n",
    "train_num = train_generator.samples\n",
    "valid_num = valid_generator.samples\n",
    "print(train_num)\n",
    "print(valid_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 16)      448       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 1,345,764\n",
      "Trainable params: 1,345,284\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, padding='same',\n",
    "                        activation='relu', input_shape=[width, height, channels]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=3, padding='same',\n",
    "                        activation='relu'),\n",
    "    #keras.layers.SpatialDropout2D(0.5),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=32, kernel_size=3, padding='same',\n",
    "                        activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=3, padding='same',\n",
    "                        activation='relu'),\n",
    "    #keras.layers.SpatialDropout2D(0.5),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, padding='same',\n",
    "                        activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, padding='same',\n",
    "                        activation='relu'),\n",
    "    #keras.layers.SpatialDropout2D(0.5),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, padding='same',\n",
    "                        activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, padding='same',\n",
    "                        activation='relu'),\n",
    "    #keras.layers.SpatialDropout2D(0.5),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(num_classes, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "27/27 [==============================] - 16s 584ms/step - loss: 4.0788 - accuracy: 0.2091 - val_loss: 3.0771 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "13/27 [=============>................] - ETA: 7s - loss: 2.2793 - accuracy: 0.4062"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = train_num // batch_size,\n",
    "                              epochs = epochs,\n",
    "                              validation_data = valid_generator,\n",
    "                              validation_steps = valid_num // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history, label, epcohs, min_value, max_value):\n",
    "    data = {}\n",
    "    data[label] = history.history[label]\n",
    "    data['val_'+label] = history.history['val_'+label]\n",
    "    pd.DataFrame(data).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.axis([0, epochs, min_value, max_value])\n",
    "    plt.show()\n",
    "    \n",
    "plot_learning_curves(history, 'accuracy', epochs, 0, 1)\n",
    "plot_learning_curves(history, 'loss', epochs, 0, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory = '/opt/tv/validation/validation',\n",
    "    classes = dir1,\n",
    "    target_size = (height, width),\n",
    "    batch_size = batch_size,\n",
    "    seed = 7,\n",
    "    shuffle = False,\n",
    "    class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = model.predict_generator(test_generator,\n",
    "                                       workers = 10,\n",
    "                                       use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filenames = test_generator.filenames\n",
    "fullfilenames = test_generator.filepaths\n",
    "pre_class = test_generator.labels\n",
    "\n",
    "train_labels = train_generator.class_indices\n",
    "labels1 = dict(zip(train_labels.values(),train_labels.keys()))\n",
    "\n",
    "test_labels = test_generator.class_indices\n",
    "labels2 = dict(zip(test_labels.values(),test_labels.keys()))\n",
    "error_paths = []\n",
    "error_labels = []\n",
    "for i in range(len(test_predict)):\n",
    "    pre = np.argmax(test_predict[i])\n",
    "    if(labels2[pre_class[i]] != labels1[pre]):\n",
    "        error_paths.append(fullfilenames[i])\n",
    "        error_labels.append(labels1[pre])\n",
    "        print(fullfilenames[i] + ' -> ' + labels1[pre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(valid_generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    传入一个目录名列表，一个标签列表，进行显示\n",
    "'''\n",
    "\n",
    "def show_imgs_labels(n_cols, error_paths, error_labels):\n",
    "    assert len(error_paths) == len(error_labels)\n",
    "    max_num = len(error_paths)\n",
    "    n_rows = math.ceil(max_num / n_cols)    #向上取整\n",
    "    plt.figure(figsize = (n_cols * 1.4, n_rows * 1.6))\n",
    "    \n",
    "    for row in range(n_rows):\n",
    "        for col in range(n_cols):\n",
    "            index = n_cols * row + col \n",
    "            if index >= max_num:    #如果画完了就退出\n",
    "                break\n",
    "            temp_img = image.load_img(error_paths[index], target_size = (128, 128))\n",
    "            plt.subplot(n_rows, n_cols, index+1)\n",
    "            plt.imshow(temp_img, cmap=\"binary\",\n",
    "                       interpolation = 'nearest')\n",
    "            plt.axis('off')\n",
    "            plt.title(error_labels[index])\n",
    "    plt.show()\n",
    "    \n",
    "show_imgs_labels(10, error_paths, error_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
