{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from datetime import date\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from model import efficientdet\n",
    "from utils import preprocess_image, postprocess_boxes\n",
    "from augmentor.color import VisualEffect\n",
    "from augmentor.misc import MiscEffect\n",
    "from losses import smooth_l1, focal, smooth_l1_quad\n",
    "from efficientnet import BASE_WEIGHTS_PATH, WEIGHTS_HASHES\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "\n",
    "import re\n",
    "import requests\n",
    "from urllib import error\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(device=gpus[1], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ai():\n",
    "    phi = 5\n",
    "    weighted_bifpn = False\n",
    "    model_path = '/ai/EfficientDet-master/checkpoints/2020-08-12/pascal_195_0.0246_0.0184.h5'\n",
    "    image_sizes = (512, 640, 768, 896, 1024, 1280, 1408)\n",
    "    image_size = image_sizes[phi]\n",
    "    score_threshold = 0.9\n",
    "    classes = ['jz','qpl']\n",
    "    num_classes = len(classes)\n",
    "    colors = [np.random.randint(255,0,0).tolist() for _ in range(num_classes)]\n",
    "    _, model = efficientdet(phi=phi,\n",
    "                            weighted_bifpn=weighted_bifpn,\n",
    "                            num_classes=num_classes,\n",
    "                            score_threshold=score_threshold)\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "    return model\n",
    "\n",
    "model = init_ai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_url(word, page=300):\n",
    "    t = 0\n",
    "    i = 1\n",
    "    s = 0\n",
    "    url_list = list()\n",
    "    url = 'http://image.baidu.com/search/flip?tn=baiduimage&ie=utf-8&word=' + word + '&pn='\n",
    "    while t < page:\n",
    "        Url = url + str(t)\n",
    "        try:\n",
    "            Result = requests.get(Url, timeout=7)\n",
    "        except BaseException:\n",
    "            t = t + 60\n",
    "            continue\n",
    "        else:\n",
    "            result = Result.text\n",
    "            pic_url = re.findall('\"objURL\":\"(.*?)\",', result, re.S)  # 先利用正则表达式找到图片url\n",
    "            if len(pic_url) == 0:\n",
    "                break\n",
    "            else:\n",
    "                url_list = url_list + pic_url\n",
    "                t = t + 60\n",
    "    return {'keyword':word, 'urls':url_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai_process(model, key_url_dict, out_path = ''):\n",
    "    i = 0\n",
    "    keyword = key_url_dict['keyword']\n",
    "    url_list = key_url_dict['urls']\n",
    "    for url in url_list:\n",
    "        try:\n",
    "            print(url)\n",
    "            pic = requests.get(url, timeout=7)\n",
    "            \n",
    "            image = np.asarray(bytearray(pic.content), dtype=\"uint8\")\n",
    "            image = cv2.imdecode(image, cv2.IMREAD_COLOR)              \n",
    "            \n",
    "            src_image = image.copy()\n",
    "            \n",
    "            # BGR -> RGB\n",
    "            image = image[:, :, ::-1]\n",
    "            h, w = image.shape[:2]\n",
    "            image_sizes = (512, 640, 768, 896, 1024, 1280, 1408)\n",
    "            \n",
    "            score_threshold = 0.9\n",
    "            \n",
    "            phi = 5\n",
    "            image_size = image_sizes[phi]\n",
    "            image, scale = preprocess_image(image, image_size=image_size)\n",
    "            # run network\n",
    "            start = time.time()\n",
    "            boxes, scores, labels = model.predict_on_batch([np.expand_dims(image, axis=0)])\n",
    "            boxes, scores, labels = np.squeeze(boxes), np.squeeze(scores), np.squeeze(labels)\n",
    "            boxes = postprocess_boxes(boxes=boxes, scale=scale, height=h, width=w)\n",
    "            # select indices which have a score above the threshold\n",
    "            indices = np.where(scores[:] > score_threshold)[0]\n",
    "\n",
    "            # select those detections\n",
    "            boxes = boxes[indices]\n",
    "            \n",
    "            sku_path = out_path + keyword\n",
    "            if not os.path.exists(sku_path):\n",
    "                os.mkdir(sku_path)\n",
    "            \n",
    "            for bbox in boxes:\n",
    "                bbs = BoundingBoxesOnImage([BoundingBox(x1=int(bbox[0]), x2=int(bbox[2]), y1=int(bbox[1]), y2=int(bbox[3]))], shape=src_image.shape)\n",
    "                bbox_img = bbs.bounding_boxes[0].extract_from_image(src_image)    \n",
    "                cv2.imwrite(sku_path + '/' + keyword + str(i) + '.jpg', bbox_img)\n",
    "                i = i + 1\n",
    "        except:\n",
    "            next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku = ['万宝路(软红)',\n",
    " '中华(硬)',\n",
    " '中华(软)',\n",
    " '中南海(8mg)',\n",
    " '云烟(软紫)',\n",
    " '长白山(777)',\n",
    " '七匹狼(锋芒)',\n",
    " '双喜(软国际)',\n",
    " '泰山(儒风细支)',\n",
    " '泰山(华贵)',\n",
    " '泰山(大鸡)',\n",
    " '泰山(好好学习)',\n",
    " '泰山(好客细支)',\n",
    " '泰山(宏图)',\n",
    " '泰山(平安)',\n",
    " '泰山(心悦)',\n",
    " '泰山(新品)',\n",
    " '黄鹤楼(硬红)',\n",
    " '泰山(白将军)',\n",
    " '泰山(硬红八喜)',\n",
    " '泰山(红将军)',\n",
    " '泰山(青秀)',\n",
    " '黄鹤楼(天下名楼)',\n",
    " '泰山(颜悦)',\n",
    " '玉溪(初心)',\n",
    " '黄金叶(金满堂)',\n",
    " '玉溪(软)',\n",
    " '玉溪(阿诗玛)',\n",
    " '黄金叶(爱尚)',\n",
    " '黄金叶(喜满堂)',\n",
    " '苏烟(五星红杉树）',\n",
    " '苏烟(软金砂)',\n",
    " '钻石(荷花)',\n",
    " '长白山(红)',\n",
    " '黄果树(长征)',\n",
    " '红旗渠(芒果)',\n",
    " '天子(金)',\n",
    " '红旗渠(雪茄)',\n",
    " '黄金叶(大M)',\n",
    " '红双喜(硬)',\n",
    " '白沙(硬精品三代)',\n",
    " '555(双冰)',\n",
    " '中南海(5mg)',\n",
    " '利群(软长嘴)',\n",
    " '金圣(硬滕王阁)',\n",
    " '黄山(硬记忆)',\n",
    " '泰山(皇家礼炮)',\n",
    " '利群(软红长嘴)',\n",
    " '555(配方555·金锐)',\n",
    " '牡丹(软)',\n",
    " '娇子(宽窄好运)',\n",
    " '娇子(蓝)',\n",
    " '娇子(时代阳光)',\n",
    " '娇子(五粮醇香)',\n",
    " '利群(蓝天)',\n",
    " '利群(新版)',\n",
    " '南京(红)',\n",
    " '南京(炫赫门)',\n",
    " '云烟(紫)',\n",
    " '555(冰炫细支)',\n",
    " '黄山(印象一品)',\n",
    " '南京(十二钗薄荷)',\n",
    " '娇子(格调细支)',\n",
    " '南京(十二钗烤烟)',\n",
    " '南京(雨花石)',\n",
    " '七匹狼(红)',\n",
    " '云烟(软珍品)',\n",
    " '云烟(细支云龙)',\n",
    " '七匹狼(豪情)',\n",
    " '真龙(经典红)',\n",
    " '黄山(红方印细支)',\n",
    " '黄山(记忆)',\n",
    " '黄山(新一品)',\n",
    " '娇子(X)',\n",
    " '红河(小熊猫世纪风)',\n",
    " '好猫(长乐)',\n",
    " '真龙(凌云)',\n",
    " '哈德门(软)',\n",
    " '哈德门(纯香)',\n",
    " '白沙(精品二代)',\n",
    " '白沙(硬)',\n",
    " '芙蓉王(硬)',\n",
    " '贵烟(跨越)',\n",
    " '红塔山(软经典)',\n",
    " '红塔山(硬经典100)',\n",
    " '黄鹤楼(软蓝)',\n",
    " '黄金叶(乐途)',\n",
    " '黄金叶(小目标)',\n",
    " '娇子(宽窄如意)',\n",
    " '七匹狼(白)',\n",
    " '长城(醇雅陈皮薄荷)',\n",
    " '石狮(软富健)']\n",
    "\n",
    "image_path = '/ai/data/debug/'\n",
    "\n",
    "for keyword in sku:\n",
    "    print('开始爬取：' + keyword)\n",
    "    key_url_dict = crawl_url(keyword)\n",
    "    ai_process(model, key_url_dict, image_path)\n",
    "    print('爬取结束!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
