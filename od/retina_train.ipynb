{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import keras\n",
    "import keras.preprocessing.image\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "sys.path.append(\"/ai/keras-retinanet-master\")\n",
    "\n",
    "# Change these to absolute imports if you copy this script outside the keras_retinanet package.\n",
    "from keras_retinanet import layers  # noqa: F401\n",
    "from keras_retinanet import losses\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.callbacks import RedirectModel\n",
    "from keras_retinanet.callbacks.eval import Evaluate\n",
    "from keras_retinanet.models.retinanet import retinanet_bbox\n",
    "from keras_retinanet.preprocessing.csv_generator import CSVGenerator\n",
    "from keras_retinanet.preprocessing.kitti import KittiGenerator\n",
    "from keras_retinanet.preprocessing.open_images import OpenImagesGenerator\n",
    "from keras_retinanet.preprocessing.pascal_voc import PascalVocGenerator\n",
    "from keras_retinanet.utils.anchors import make_shapes_callback\n",
    "from keras_retinanet.utils.config import read_config_file, parse_anchor_parameters\n",
    "from keras_retinanet.utils.keras_version import check_keras_version\n",
    "from keras_retinanet.utils.model import freeze as freeze_model\n",
    "from keras_retinanet.utils.transform import random_transform_generator\n",
    "from keras_retinanet.utils.tf_version import check_tf_version\n",
    "from keras_retinanet.utils.gpu import setup_gpu\n",
    "from keras_retinanet.utils.transform import random_transform_generator\n",
    "from keras_retinanet.utils.image import random_visual_effect_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(device=gpus[1], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedirs(path):\n",
    "    # Intended behavior: try to create the directory,\n",
    "    # pass if the directory exists already, fails otherwise.\n",
    "    # Meant for Python 2.7/3.n compatibility.\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_with_weights(model, weights, skip_mismatch):\n",
    "    \"\"\" Load weights for model.\n",
    "\n",
    "    Args\n",
    "        model         : The model to load weights for.\n",
    "        weights       : The weights to load.\n",
    "        skip_mismatch : If True, skips layers whose shape of weights doesn't match with the model.\n",
    "    \"\"\"\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights, by_name=True, skip_mismatch=skip_mismatch)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(backbone_retinanet, num_classes, weights, multi_gpu=0,\n",
    "                  freeze_backbone=False, lr=1e-5, config=None):\n",
    "    \"\"\" Creates three models (model, training_model, prediction_model).\n",
    "\n",
    "    Args\n",
    "        backbone_retinanet : A function to call to create a retinanet model with a given backbone.\n",
    "        num_classes        : The number of classes to train.\n",
    "        weights            : The weights to load into the model.\n",
    "        multi_gpu          : The number of GPUs to use for training.\n",
    "        freeze_backbone    : If True, disables learning for the backbone.\n",
    "        config             : Config parameters, None indicates the default configuration.\n",
    "\n",
    "    Returns\n",
    "        model            : The base model. This is also the model that is saved in snapshots.\n",
    "        training_model   : The training model. If multi_gpu=0, this is identical to model.\n",
    "        prediction_model : The model wrapped with utility functions to perform object detection (applies regression values and performs NMS).\n",
    "    \"\"\"\n",
    "\n",
    "    modifier = freeze_model if freeze_backbone else None\n",
    "\n",
    "    # load anchor parameters, or pass None (so that defaults will be used)\n",
    "    anchor_params = None\n",
    "    num_anchors   = None\n",
    "    if config and 'anchor_parameters' in config:\n",
    "        anchor_params = parse_anchor_parameters(config)\n",
    "        num_anchors   = anchor_params.num_anchors()\n",
    "\n",
    "    # Keras recommends initialising a multi-gpu model on the CPU to ease weight sharing, and to prevent OOM errors.\n",
    "    # optionally wrap in a parallel model\n",
    "    if multi_gpu > 1:\n",
    "        from keras.utils import multi_gpu_model\n",
    "        with tf.device('/cpu:0'):\n",
    "            model = model_with_weights(backbone_retinanet(num_classes, num_anchors=num_anchors, modifier=modifier), weights=weights, skip_mismatch=True)\n",
    "        training_model = multi_gpu_model(model, gpus=multi_gpu)\n",
    "    else:\n",
    "        model          = model_with_weights(backbone_retinanet(num_classes, num_anchors=num_anchors, modifier=modifier), weights=weights, skip_mismatch=True)\n",
    "        training_model = model\n",
    "\n",
    "    # make prediction model\n",
    "    prediction_model = retinanet_bbox(model=model, anchor_params=anchor_params)\n",
    "\n",
    "    # compile model\n",
    "    training_model.compile(\n",
    "        loss={\n",
    "            'regression'    : losses.smooth_l1(),\n",
    "            'classification': losses.focal()\n",
    "        },\n",
    "        optimizer=keras.optimizers.adam(lr=lr, clipnorm=0.001)\n",
    "    )\n",
    "\n",
    "    return model, training_model, prediction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(model, training_model, prediction_model, validation_generator, args):\n",
    "    \"\"\" Creates the callbacks to use during training.\n",
    "\n",
    "    Args\n",
    "        model: The base model.\n",
    "        training_model: The model that is used for training.\n",
    "        prediction_model: The model that should be used for validation.\n",
    "        validation_generator: The generator for creating validation data.\n",
    "        args: parseargs args object.\n",
    "\n",
    "    Returns:\n",
    "        A list of callbacks used for training.\n",
    "    \"\"\"\n",
    "    callbacks = []\n",
    "\n",
    "    tensorboard_callback = None\n",
    "\n",
    "    if args.tensorboard_dir:\n",
    "        makedirs(args.tensorboard_dir)\n",
    "        tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "            log_dir                = args.tensorboard_dir,\n",
    "            histogram_freq         = 0,\n",
    "            batch_size             = args.batch_size,\n",
    "            write_graph            = True,\n",
    "            write_grads            = False,\n",
    "            write_images           = False,\n",
    "            embeddings_freq        = 0,\n",
    "            embeddings_layer_names = None,\n",
    "            embeddings_metadata    = None\n",
    "        )\n",
    "\n",
    "    if args.evaluation and validation_generator:\n",
    "        if args.dataset_type == 'coco':\n",
    "            from ..callbacks.coco import CocoEval\n",
    "\n",
    "            # use prediction model for evaluation\n",
    "            evaluation = CocoEval(validation_generator, tensorboard=tensorboard_callback)\n",
    "        else:\n",
    "            evaluation = Evaluate(validation_generator, tensorboard=tensorboard_callback, weighted_average=args.weighted_average)\n",
    "        evaluation = RedirectModel(evaluation, prediction_model)\n",
    "        callbacks.append(evaluation)\n",
    "\n",
    "    # save the model\n",
    "    if args.snapshots:\n",
    "        # ensure directory created first; otherwise h5py will error after epoch.\n",
    "        makedirs(args.snapshot_path)\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "            os.path.join(\n",
    "                args.snapshot_path,\n",
    "                '{backbone}_{dataset_type}_{{epoch:02d}}.h5'.format(backbone=args.backbone, dataset_type=args.dataset_type)\n",
    "            ),\n",
    "            verbose=1,\n",
    "            # save_best_only=True,\n",
    "            # monitor=\"mAP\",\n",
    "            # mode='max'\n",
    "        )\n",
    "        checkpoint = RedirectModel(checkpoint, model)\n",
    "        callbacks.append(checkpoint)\n",
    "\n",
    "    callbacks.append(keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor    = 'loss',\n",
    "        factor     = args.reduce_lr_factor,\n",
    "        patience   = args.reduce_lr_patience,\n",
    "        verbose    = 1,\n",
    "        mode       = 'auto',\n",
    "        min_delta  = 0.0001,\n",
    "        cooldown   = 0,\n",
    "        min_lr     = 0\n",
    "    ))\n",
    "\n",
    "#     callbacks.append(keras.callbacks.EarlyStopping(\n",
    "#         monitor    = 'mAP',\n",
    "#         patience   = 5,\n",
    "#         mode       = 'max',\n",
    "#         min_delta  = 0.01\n",
    "#     ))\n",
    "\n",
    "    if args.tensorboard_dir:\n",
    "        callbacks.append(tensorboard_callback)\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generators(args, preprocess_image):\n",
    "    \"\"\" Create generators for training and validation.\n",
    "\n",
    "    Args\n",
    "        args             : parseargs object containing configuration for generators.\n",
    "        preprocess_image : Function that preprocesses an image for the network.\n",
    "    \"\"\"\n",
    "    common_args = {\n",
    "        'batch_size'       : args.batch_size,\n",
    "        'config'           : args.config,\n",
    "        'image_min_side'   : args.image_min_side,\n",
    "        'image_max_side'   : args.image_max_side,\n",
    "        'no_resize'        : args.no_resize,\n",
    "        'preprocess_image' : preprocess_image,\n",
    "    }\n",
    "\n",
    "    # create random transform generator for augmenting training data\n",
    "    if args.random_transform:\n",
    "        transform_generator = random_transform_generator(\n",
    "            min_rotation=-0.1,\n",
    "            max_rotation=0.1,\n",
    "            min_translation=(-0.1, -0.1),\n",
    "            max_translation=(0.1, 0.1),\n",
    "            min_shear=-0.1,\n",
    "            max_shear=0.1,\n",
    "            min_scaling=(0.9, 0.9),\n",
    "            max_scaling=(1.1, 1.1),\n",
    "            flip_x_chance=0.5,\n",
    "            flip_y_chance=0.5,\n",
    "        )\n",
    "        visual_effect_generator = random_visual_effect_generator(\n",
    "            contrast_range=(0.9, 1.1),\n",
    "            brightness_range=(-.1, .1),\n",
    "            hue_range=(-0.05, 0.05),\n",
    "            saturation_range=(0.95, 1.05)\n",
    "        )\n",
    "    else:\n",
    "        transform_generator = random_transform_generator(flip_x_chance=0.5)\n",
    "        visual_effect_generator = None\n",
    "\n",
    "    if args.dataset_type == 'coco':\n",
    "        # import here to prevent unnecessary dependency on cocoapi\n",
    "        from ..preprocessing.coco import CocoGenerator\n",
    "\n",
    "        train_generator = CocoGenerator(\n",
    "            args.coco_path,\n",
    "            'train2017',\n",
    "            transform_generator=transform_generator,\n",
    "            visual_effect_generator=visual_effect_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        validation_generator = CocoGenerator(\n",
    "            args.coco_path,\n",
    "            'val2017',\n",
    "            shuffle_groups=False,\n",
    "            **common_args\n",
    "        )\n",
    "    elif args.dataset_type == 'pascal':\n",
    "        train_generator = PascalVocGenerator(\n",
    "            args.pascal_path,\n",
    "            'train',\n",
    "            classes = {'pack':0},\n",
    "            image_extension=args.image_extension,\n",
    "            transform_generator=transform_generator,\n",
    "            visual_effect_generator=visual_effect_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        validation_generator = PascalVocGenerator(\n",
    "            args.pascal_path,\n",
    "            'val',\n",
    "            classes = {'pack':0},\n",
    "            image_extension=args.image_extension,\n",
    "            shuffle_groups=False,\n",
    "            **common_args\n",
    "        )\n",
    "    elif args.dataset_type == 'csv':\n",
    "        train_generator = CSVGenerator(\n",
    "            args.annotations,\n",
    "            args.classes,\n",
    "            transform_generator=transform_generator,\n",
    "            visual_effect_generator=visual_effect_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        if args.val_annotations:\n",
    "            validation_generator = CSVGenerator(\n",
    "                args.val_annotations,\n",
    "                args.classes,\n",
    "                shuffle_groups=False,\n",
    "                **common_args\n",
    "            )\n",
    "        else:\n",
    "            validation_generator = None\n",
    "    elif args.dataset_type == 'oid':\n",
    "        train_generator = OpenImagesGenerator(\n",
    "            args.main_dir,\n",
    "            subset='train',\n",
    "            version=args.version,\n",
    "            labels_filter=args.labels_filter,\n",
    "            annotation_cache_dir=args.annotation_cache_dir,\n",
    "            parent_label=args.parent_label,\n",
    "            transform_generator=transform_generator,\n",
    "            visual_effect_generator=visual_effect_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        validation_generator = OpenImagesGenerator(\n",
    "            args.main_dir,\n",
    "            subset='validation',\n",
    "            version=args.version,\n",
    "            labels_filter=args.labels_filter,\n",
    "            annotation_cache_dir=args.annotation_cache_dir,\n",
    "            parent_label=args.parent_label,\n",
    "            shuffle_groups=False,\n",
    "            **common_args\n",
    "        )\n",
    "    elif args.dataset_type == 'kitti':\n",
    "        train_generator = KittiGenerator(\n",
    "            args.kitti_path,\n",
    "            subset='train',\n",
    "            transform_generator=transform_generator,\n",
    "            visual_effect_generator=visual_effect_generator,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        validation_generator = KittiGenerator(\n",
    "            args.kitti_path,\n",
    "            subset='val',\n",
    "            shuffle_groups=False,\n",
    "            **common_args\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('Invalid data type received: {}'.format(args.dataset_type))\n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_args(parsed_args):\n",
    "    \"\"\" Function to check for inherent contradictions within parsed arguments.\n",
    "    For example, batch_size < num_gpus\n",
    "    Intended to raise errors prior to backend initialisation.\n",
    "\n",
    "    Args\n",
    "        parsed_args: parser.parse_args()\n",
    "\n",
    "    Returns\n",
    "        parsed_args\n",
    "    \"\"\"\n",
    "\n",
    "    if parsed_args.multi_gpu > 1 and parsed_args.batch_size < parsed_args.multi_gpu:\n",
    "        raise ValueError(\n",
    "            \"Batch size ({}) must be equal to or higher than the number of GPUs ({})\".format(parsed_args.batch_size,\n",
    "                                                                                             parsed_args.multi_gpu))\n",
    "\n",
    "    if parsed_args.multi_gpu > 1 and parsed_args.snapshot:\n",
    "        raise ValueError(\n",
    "            \"Multi GPU training ({}) and resuming from snapshots ({}) is not supported.\".format(parsed_args.multi_gpu,\n",
    "                                                                                                parsed_args.snapshot))\n",
    "\n",
    "    if parsed_args.multi_gpu > 1 and not parsed_args.multi_gpu_force:\n",
    "        raise ValueError(\"Multi-GPU support is experimental, use at own risk! Run with --multi-gpu-force if you wish to continue.\")\n",
    "\n",
    "    if 'resnet' not in parsed_args.backbone:\n",
    "        warnings.warn('Using experimental backbone {}. Only resnet50 has been properly tested.'.format(parsed_args.backbone))\n",
    "\n",
    "    return parsed_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args):\n",
    "    \"\"\" Parse the arguments.\n",
    "    \"\"\"\n",
    "    parser     = argparse.ArgumentParser(description='Simple training script for training a RetinaNet network.')\n",
    "    subparsers = parser.add_subparsers(help='Arguments for specific dataset types.', dest='dataset_type')\n",
    "    subparsers.required = True\n",
    "\n",
    "    coco_parser = subparsers.add_parser('coco')\n",
    "    coco_parser.add_argument('coco_path', help='Path to dataset directory (ie. /tmp/COCO).')\n",
    "\n",
    "    pascal_parser = subparsers.add_parser('pascal')\n",
    "    pascal_parser.add_argument('pascal_path', help='Path to dataset directory (ie. /tmp/VOCdevkit).')\n",
    "    pascal_parser.add_argument('--image-extension',   help='Declares the dataset images\\' extension.', default='.jpg')\n",
    "\n",
    "    kitti_parser = subparsers.add_parser('kitti')\n",
    "    kitti_parser.add_argument('kitti_path', help='Path to dataset directory (ie. /tmp/kitti).')\n",
    "\n",
    "    def csv_list(string):\n",
    "        return string.split(',')\n",
    "\n",
    "    oid_parser = subparsers.add_parser('oid')\n",
    "    oid_parser.add_argument('main_dir', help='Path to dataset directory.')\n",
    "    oid_parser.add_argument('--version',  help='The current dataset version is v4.', default='v4')\n",
    "    oid_parser.add_argument('--labels-filter',  help='A list of labels to filter.', type=csv_list, default=None)\n",
    "    oid_parser.add_argument('--annotation-cache-dir', help='Path to store annotation cache.', default='.')\n",
    "    oid_parser.add_argument('--parent-label', help='Use the hierarchy children of this label.', default=None)\n",
    "\n",
    "    csv_parser = subparsers.add_parser('csv')\n",
    "    csv_parser.add_argument('annotations', help='Path to CSV file containing annotations for training.')\n",
    "    csv_parser.add_argument('classes', help='Path to a CSV file containing class label mapping.')\n",
    "    csv_parser.add_argument('--val-annotations', help='Path to CSV file containing annotations for validation (optional).')\n",
    "\n",
    "    group = parser.add_mutually_exclusive_group()\n",
    "    group.add_argument('--snapshot',          help='Resume training from a snapshot.')\n",
    "    group.add_argument('--imagenet-weights',  help='Initialize the model with pretrained imagenet weights. This is the default behaviour.', action='store_const', const=True, default=True)\n",
    "    group.add_argument('--weights',           help='Initialize the model with weights from a file.')\n",
    "    group.add_argument('--no-weights',        help='Don\\'t initialize the model with any weights.', dest='imagenet_weights', action='store_const', const=False)\n",
    "    parser.add_argument('--backbone',         help='Backbone model used by retinanet.', default='resnet50', type=str)\n",
    "    parser.add_argument('--batch-size',       help='Size of the batches.', default=1, type=int)\n",
    "    parser.add_argument('--gpu',              help='Id of the GPU to use (as reported by nvidia-smi).', type=int)\n",
    "    parser.add_argument('--multi-gpu',        help='Number of GPUs to use for parallel processing.', type=int, default=0)\n",
    "    parser.add_argument('--multi-gpu-force',  help='Extra flag needed to enable (experimental) multi-gpu support.', action='store_true')\n",
    "    parser.add_argument('--initial-epoch',    help='Epoch from which to begin the train, useful if resuming from snapshot.', type=int, default=0)\n",
    "    parser.add_argument('--epochs',           help='Number of epochs to train.', type=int, default=50)\n",
    "    parser.add_argument('--steps',            help='Number of steps per epoch.', type=int, default=10000)\n",
    "    parser.add_argument('--lr',               help='Learning rate.', type=float, default=1e-5)\n",
    "    parser.add_argument('--snapshot-path',    help='Path to store snapshots of models during training (defaults to \\'./snapshots\\')', default='./snapshots')\n",
    "    parser.add_argument('--tensorboard-dir',  help='Log directory for Tensorboard output', default='./logs') #=> https://github.com/tensorflow/tensorflow/pull/34870\n",
    "    parser.add_argument('--no-snapshots',     help='Disable saving snapshots.', dest='snapshots', action='store_false')\n",
    "    parser.add_argument('--no-evaluation',    help='Disable per epoch evaluation.', dest='evaluation', action='store_false')\n",
    "    parser.add_argument('--freeze-backbone',  help='Freeze training of backbone layers.', action='store_true')\n",
    "    parser.add_argument('--random-transform', help='Randomly transform image and annotations.', action='store_true')\n",
    "    parser.add_argument('--image-min-side',   help='Rescale the image so the smallest side is min_side.', type=int, default=800)\n",
    "    parser.add_argument('--image-max-side',   help='Rescale the image if the largest side is larger than max_side.', type=int, default=1333)\n",
    "    parser.add_argument('--no-resize',        help='Don''t rescale the image.', action='store_true')\n",
    "    parser.add_argument('--config',           help='Path to a configuration parameters .ini file.')\n",
    "    parser.add_argument('--weighted-average', help='Compute the mAP using the weighted average of precisions among classes.', action='store_true')\n",
    "    parser.add_argument('--compute-val-loss', help='Compute validation loss during training', dest='compute_val_loss', action='store_true')\n",
    "    parser.add_argument('--reduce-lr-patience', help='Reduce learning rate after validation loss decreases over reduce_lr_patience epochs', type=int, default=2)\n",
    "    parser.add_argument('--reduce-lr-factor', help='When learning rate is reduced due to reduce_lr_patience, multiply by reduce_lr_factor', type=float, default=0.1)\n",
    "\n",
    "    # Fit generator arguments\n",
    "    parser.add_argument('--multiprocessing',  help='Use multiprocessing in fit_generator.', action='store_true')\n",
    "    parser.add_argument('--workers',          help='Number of generator workers.', type=int, default=1)\n",
    "    parser.add_argument('--max-queue-size',   help='Queue length for multiprocessing workers in fit_generator.', type=int, default=10)\n",
    "\n",
    "    return check_args(parser.parse_args(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args=None):\n",
    "    # parse arguments\n",
    "    if args is None:\n",
    "        args = sys.argv[1:]\n",
    "    args = parse_args(args)\n",
    "\n",
    "    # create object that stores backbone information\n",
    "    backbone = models.backbone(args.backbone)\n",
    "\n",
    "    # make sure keras and tensorflow are the minimum required version\n",
    "    check_keras_version()\n",
    "    check_tf_version()\n",
    "\n",
    "    # optionally choose specific GPU\n",
    "    if args.gpu is not None:\n",
    "        setup_gpu(args.gpu)\n",
    "\n",
    "    # optionally load config parameters\n",
    "    if args.config:\n",
    "        args.config = read_config_file(args.config)\n",
    "\n",
    "    # create the generators\n",
    "    train_generator, validation_generator = create_generators(args, backbone.preprocess_image)\n",
    "\n",
    "    # create the model\n",
    "    if args.snapshot is not None:\n",
    "        print('Loading model, this may take a second...')\n",
    "        model            = models.load_model(args.snapshot, backbone_name=args.backbone)\n",
    "        training_model   = model\n",
    "        anchor_params    = None\n",
    "        if args.config and 'anchor_parameters' in args.config:\n",
    "            anchor_params = parse_anchor_parameters(args.config)\n",
    "        prediction_model = retinanet_bbox(model=model, anchor_params=anchor_params)\n",
    "    else:\n",
    "        weights = args.weights\n",
    "        # default to imagenet if nothing else is specified\n",
    "        if weights is None and args.imagenet_weights:\n",
    "            weights = backbone.download_imagenet()\n",
    "\n",
    "        print('Creating model, this may take a second...')\n",
    "        model, training_model, prediction_model = create_models(\n",
    "            backbone_retinanet=backbone.retinanet,\n",
    "            num_classes=train_generator.num_classes(),\n",
    "            weights=weights,\n",
    "            multi_gpu=args.multi_gpu,\n",
    "            freeze_backbone=args.freeze_backbone,\n",
    "            lr=args.lr,\n",
    "            config=args.config\n",
    "        )\n",
    "\n",
    "    # print model summary\n",
    "#     print(model.summary())\n",
    "\n",
    "    # this lets the generator compute backbone layer shapes using the actual backbone model\n",
    "    if 'vgg' in args.backbone or 'densenet' in args.backbone:\n",
    "        train_generator.compute_shapes = make_shapes_callback(model)\n",
    "        if validation_generator:\n",
    "            validation_generator.compute_shapes = train_generator.compute_shapes\n",
    "\n",
    "    # create the callbacks\n",
    "    callbacks = create_callbacks(\n",
    "        model,\n",
    "        training_model,\n",
    "        prediction_model,\n",
    "        validation_generator,\n",
    "        args,\n",
    "    )\n",
    "\n",
    "    if not args.compute_val_loss:\n",
    "        validation_generator = None\n",
    "\n",
    "    # start training\n",
    "    return training_model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=args.steps,\n",
    "        epochs=args.epochs,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        workers=args.workers,\n",
    "        use_multiprocessing=args.multiprocessing,\n",
    "        max_queue_size=args.max_queue_size,\n",
    "        validation_data=validation_generator,\n",
    "        initial_epoch=args.initial_epoch\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPUs\n",
      "Creating model, this may take a second...\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
      "array([[-22.627417, -11.313708,  22.627417,  11.313708],\n",
      "       [-28.50876 , -14.25438 ,  28.50876 ,  14.25438 ],\n",
      "       [-35.918785, -17.959393,  35.918785,  17.959393],\n",
      "       [-16.      , -16.      ,  16.      ,  16.      ],\n",
      "       [-20.158737, -20.158737,  20.158737,  20.158737],\n",
      "       [-25.398417, -25.398417,  25.398417,  25.398417],\n",
      "       [-11.313708, -22.627417,  11.313708,  22.627417],\n",
      "       [-14.25438 , -28.50876 ,  14.25438 ,  28.50876 ],\n",
      "       [-17.959393, -35.918785,  17.959393,  35.918785]], dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
      "array([[-45.254833, -22.627417,  45.254833,  22.627417],\n",
      "       [-57.01752 , -28.50876 ,  57.01752 ,  28.50876 ],\n",
      "       [-71.83757 , -35.918785,  71.83757 ,  35.918785],\n",
      "       [-32.      , -32.      ,  32.      ,  32.      ],\n",
      "       [-40.317474, -40.317474,  40.317474,  40.317474],\n",
      "       [-50.796833, -50.796833,  50.796833,  50.796833],\n",
      "       [-22.627417, -45.254833,  22.627417,  45.254833],\n",
      "       [-28.50876 , -57.01752 ,  28.50876 ,  57.01752 ],\n",
      "       [-35.918785, -71.83757 ,  35.918785,  71.83757 ]], dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
      "array([[ -90.50967 ,  -45.254833,   90.50967 ,   45.254833],\n",
      "       [-114.03504 ,  -57.01752 ,  114.03504 ,   57.01752 ],\n",
      "       [-143.67514 ,  -71.83757 ,  143.67514 ,   71.83757 ],\n",
      "       [ -64.      ,  -64.      ,   64.      ,   64.      ],\n",
      "       [ -80.63495 ,  -80.63495 ,   80.63495 ,   80.63495 ],\n",
      "       [-101.593666, -101.593666,  101.593666,  101.593666],\n",
      "       [ -45.254833,  -90.50967 ,   45.254833,   90.50967 ],\n",
      "       [ -57.01752 , -114.03504 ,   57.01752 ,  114.03504 ],\n",
      "       [ -71.83757 , -143.67514 ,   71.83757 ,  143.67514 ]],\n",
      "      dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
      "array([[-181.01933,  -90.50967,  181.01933,   90.50967],\n",
      "       [-228.07008, -114.03504,  228.07008,  114.03504],\n",
      "       [-287.35028, -143.67514,  287.35028,  143.67514],\n",
      "       [-128.     , -128.     ,  128.     ,  128.     ],\n",
      "       [-161.2699 , -161.2699 ,  161.2699 ,  161.2699 ],\n",
      "       [-203.18733, -203.18733,  203.18733,  203.18733],\n",
      "       [ -90.50967, -181.01933,   90.50967,  181.01933],\n",
      "       [-114.03504, -228.07008,  114.03504,  228.07008],\n",
      "       [-143.67514, -287.35028,  143.67514,  287.35028]], dtype=float32)> anchors\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
      "array([[-362.03867, -181.01933,  362.03867,  181.01933],\n",
      "       [-456.14017, -228.07008,  456.14017,  228.07008],\n",
      "       [-574.70056, -287.35028,  574.70056,  287.35028],\n",
      "       [-256.     , -256.     ,  256.     ,  256.     ],\n",
      "       [-322.5398 , -322.5398 ,  322.5398 ,  322.5398 ],\n",
      "       [-406.37466, -406.37466,  406.37466,  406.37466],\n",
      "       [-181.01933, -362.03867,  181.01933,  362.03867],\n",
      "       [-228.07008, -456.14017,  228.07008,  456.14017],\n",
      "       [-287.35028, -574.70056,  287.35028,  574.70056]], dtype=float32)> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/lib/python3.7/site-packages/keras/callbacks/tensorboard_v2.py:92: UserWarning: The TensorBoard callback `batch_size` argument (for histogram computation) is deprecated with TensorFlow 2.0. It will be ignored.\n",
      "  warnings.warn('The TensorBoard callback `batch_size` argument '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 603s 1s/step - loss: 3.0159 - regression_loss: 2.4485 - classification_loss: 0.5674 - val_loss: 2.5255 - val_regression_loss: 2.2231 - val_classification_loss: 0.3596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:23 Time:  0:00:23\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.0959\n",
      "mAP: 0.0959\n",
      "\n",
      "Epoch 00001: saving model to ./snapshots/resnet50_pascal_01.h5\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 604s 1s/step - loss: 2.2067 - regression_loss: 1.8908 - classification_loss: 0.3160 - val_loss: 2.0654 - val_regression_loss: 1.7190 - val_classification_loss: 0.3244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:19 Time:  0:00:19\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.2501\n",
      "mAP: 0.2501\n",
      "\n",
      "Epoch 00002: saving model to ./snapshots/resnet50_pascal_02.h5\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 569s 1s/step - loss: 1.7736 - regression_loss: 1.4908 - classification_loss: 0.2828 - val_loss: 1.7811 - val_regression_loss: 1.4140 - val_classification_loss: 0.2967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.3911\n",
      "mAP: 0.3911\n",
      "\n",
      "Epoch 00003: saving model to ./snapshots/resnet50_pascal_03.h5\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 589s 1s/step - loss: 1.5764 - regression_loss: 1.3209 - classification_loss: 0.2556 - val_loss: 1.6483 - val_regression_loss: 1.2994 - val_classification_loss: 0.2462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.6194\n",
      "mAP: 0.6194\n",
      "\n",
      "Epoch 00004: saving model to ./snapshots/resnet50_pascal_04.h5\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 569s 1s/step - loss: 1.4399 - regression_loss: 1.2207 - classification_loss: 0.2192 - val_loss: 1.4903 - val_regression_loss: 1.1972 - val_classification_loss: 0.2163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.7359\n",
      "mAP: 0.7359\n",
      "\n",
      "Epoch 00005: saving model to ./snapshots/resnet50_pascal_05.h5\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 598s 1s/step - loss: 1.3201 - regression_loss: 1.1285 - classification_loss: 0.1916 - val_loss: 1.5334 - val_regression_loss: 1.3149 - val_classification_loss: 0.1892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.7874\n",
      "mAP: 0.7874\n",
      "\n",
      "Epoch 00006: saving model to ./snapshots/resnet50_pascal_06.h5\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 589s 1s/step - loss: 1.2447 - regression_loss: 1.0703 - classification_loss: 0.1744 - val_loss: 1.3374 - val_regression_loss: 1.1102 - val_classification_loss: 0.1826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8012\n",
      "mAP: 0.8012\n",
      "\n",
      "Epoch 00007: saving model to ./snapshots/resnet50_pascal_07.h5\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 600s 1s/step - loss: 1.1912 - regression_loss: 1.0279 - classification_loss: 0.1633 - val_loss: 1.2036 - val_regression_loss: 1.0039 - val_classification_loss: 0.1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8111\n",
      "mAP: 0.8111\n",
      "\n",
      "Epoch 00008: saving model to ./snapshots/resnet50_pascal_08.h5\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 591s 1s/step - loss: 1.1391 - regression_loss: 0.9879 - classification_loss: 0.1511 - val_loss: 1.1970 - val_regression_loss: 1.0018 - val_classification_loss: 0.1639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8242\n",
      "mAP: 0.8242\n",
      "\n",
      "Epoch 00009: saving model to ./snapshots/resnet50_pascal_09.h5\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 576s 1s/step - loss: 1.1193 - regression_loss: 0.9714 - classification_loss: 0.1479 - val_loss: 1.1523 - val_regression_loss: 0.9551 - val_classification_loss: 0.1533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8300\n",
      "mAP: 0.8300\n",
      "\n",
      "Epoch 00010: saving model to ./snapshots/resnet50_pascal_10.h5\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 615s 1s/step - loss: 1.0756 - regression_loss: 0.9355 - classification_loss: 0.1402 - val_loss: 1.0878 - val_regression_loss: 0.9333 - val_classification_loss: 0.1507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8290\n",
      "mAP: 0.8290\n",
      "\n",
      "Epoch 00011: saving model to ./snapshots/resnet50_pascal_11.h5\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 602s 1s/step - loss: 1.0669 - regression_loss: 0.9287 - classification_loss: 0.1382 - val_loss: 1.1283 - val_regression_loss: 0.9419 - val_classification_loss: 0.1488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8341\n",
      "mAP: 0.8341\n",
      "\n",
      "Epoch 00012: saving model to ./snapshots/resnet50_pascal_12.h5\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 581s 1s/step - loss: 1.0484 - regression_loss: 0.9128 - classification_loss: 0.1356 - val_loss: 1.1263 - val_regression_loss: 0.9389 - val_classification_loss: 0.1468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8344\n",
      "mAP: 0.8344\n",
      "\n",
      "Epoch 00013: saving model to ./snapshots/resnet50_pascal_13.h5\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 590s 1s/step - loss: 1.0078 - regression_loss: 0.8786 - classification_loss: 0.1292 - val_loss: 1.1012 - val_regression_loss: 0.9660 - val_classification_loss: 0.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8374\n",
      "mAP: 0.8374\n",
      "\n",
      "Epoch 00014: saving model to ./snapshots/resnet50_pascal_14.h5\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 572s 1s/step - loss: 1.0010 - regression_loss: 0.8727 - classification_loss: 0.1283 - val_loss: 1.0367 - val_regression_loss: 0.8556 - val_classification_loss: 0.1430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8400\n",
      "mAP: 0.8400\n",
      "\n",
      "Epoch 00015: saving model to ./snapshots/resnet50_pascal_15.h5\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 590s 1s/step - loss: 0.9880 - regression_loss: 0.8621 - classification_loss: 0.1260 - val_loss: 1.0371 - val_regression_loss: 0.8801 - val_classification_loss: 0.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8394\n",
      "mAP: 0.8394\n",
      "\n",
      "Epoch 00016: saving model to ./snapshots/resnet50_pascal_16.h5\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 581s 1s/step - loss: 0.9667 - regression_loss: 0.8462 - classification_loss: 0.1205 - val_loss: 1.0209 - val_regression_loss: 0.8973 - val_classification_loss: 0.1378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8427\n",
      "mAP: 0.8427\n",
      "\n",
      "Epoch 00017: saving model to ./snapshots/resnet50_pascal_17.h5\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 595s 1s/step - loss: 0.9568 - regression_loss: 0.8350 - classification_loss: 0.1218 - val_loss: 0.9713 - val_regression_loss: 0.8303 - val_classification_loss: 0.1330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8461\n",
      "mAP: 0.8461\n",
      "\n",
      "Epoch 00018: saving model to ./snapshots/resnet50_pascal_18.h5\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 589s 1s/step - loss: 0.9467 - regression_loss: 0.8276 - classification_loss: 0.1191 - val_loss: 1.0032 - val_regression_loss: 0.8988 - val_classification_loss: 0.1339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8477\n",
      "mAP: 0.8477\n",
      "\n",
      "Epoch 00019: saving model to ./snapshots/resnet50_pascal_19.h5\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 591s 1s/step - loss: 0.9159 - regression_loss: 0.8003 - classification_loss: 0.1156 - val_loss: 1.0019 - val_regression_loss: 0.8904 - val_classification_loss: 0.1315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:24 Time:  0:00:24\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8462\n",
      "mAP: 0.8462\n",
      "\n",
      "Epoch 00020: saving model to ./snapshots/resnet50_pascal_20.h5\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 592s 1s/step - loss: 0.9344 - regression_loss: 0.8173 - classification_loss: 0.1171 - val_loss: 0.9989 - val_regression_loss: 0.8631 - val_classification_loss: 0.1336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8496\n",
      "mAP: 0.8496\n",
      "\n",
      "Epoch 00021: saving model to ./snapshots/resnet50_pascal_21.h5\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 565s 1s/step - loss: 0.9010 - regression_loss: 0.7891 - classification_loss: 0.1119 - val_loss: 0.9868 - val_regression_loss: 0.8264 - val_classification_loss: 0.1283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:21 Time:  0:00:21\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8465\n",
      "mAP: 0.8465\n",
      "\n",
      "Epoch 00022: saving model to ./snapshots/resnet50_pascal_22.h5\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 607s 1s/step - loss: 0.9082 - regression_loss: 0.7956 - classification_loss: 0.1126 - val_loss: 0.9773 - val_regression_loss: 0.8810 - val_classification_loss: 0.1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8478\n",
      "mAP: 0.8478\n",
      "\n",
      "Epoch 00023: saving model to ./snapshots/resnet50_pascal_23.h5\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 583s 1s/step - loss: 0.8842 - regression_loss: 0.7750 - classification_loss: 0.1092 - val_loss: 0.9220 - val_regression_loss: 0.7894 - val_classification_loss: 0.1308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8511\n",
      "mAP: 0.8511\n",
      "\n",
      "Epoch 00024: saving model to ./snapshots/resnet50_pascal_24.h5\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 588s 1s/step - loss: 0.8715 - regression_loss: 0.7624 - classification_loss: 0.1091 - val_loss: 0.9589 - val_regression_loss: 0.8427 - val_classification_loss: 0.1251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8525\n",
      "mAP: 0.8525\n",
      "\n",
      "Epoch 00025: saving model to ./snapshots/resnet50_pascal_25.h5\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 573s 1s/step - loss: 0.8639 - regression_loss: 0.7568 - classification_loss: 0.1072 - val_loss: 0.9599 - val_regression_loss: 0.8494 - val_classification_loss: 0.1254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8536\n",
      "mAP: 0.8536\n",
      "\n",
      "Epoch 00026: saving model to ./snapshots/resnet50_pascal_26.h5\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 620s 1s/step - loss: 0.8447 - regression_loss: 0.7412 - classification_loss: 0.1035 - val_loss: 0.9076 - val_regression_loss: 0.7533 - val_classification_loss: 0.1223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8561\n",
      "mAP: 0.8561\n",
      "\n",
      "Epoch 00027: saving model to ./snapshots/resnet50_pascal_27.h5\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 570s 1s/step - loss: 0.8805 - regression_loss: 0.7716 - classification_loss: 0.1089 - val_loss: 0.9455 - val_regression_loss: 0.7791 - val_classification_loss: 0.1228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8569\n",
      "mAP: 0.8569\n",
      "\n",
      "Epoch 00028: saving model to ./snapshots/resnet50_pascal_28.h5\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 588s 1s/step - loss: 0.8562 - regression_loss: 0.7521 - classification_loss: 0.1040 - val_loss: 0.9330 - val_regression_loss: 0.7938 - val_classification_loss: 0.1215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8533\n",
      "mAP: 0.8533\n",
      "\n",
      "Epoch 00029: saving model to ./snapshots/resnet50_pascal_29.h5\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 582s 1s/step - loss: 0.8106 - regression_loss: 0.7098 - classification_loss: 0.1007 - val_loss: 0.8828 - val_regression_loss: 0.7626 - val_classification_loss: 0.1175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8577\n",
      "mAP: 0.8577\n",
      "\n",
      "Epoch 00030: saving model to ./snapshots/resnet50_pascal_30.h5\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 574s 1s/step - loss: 0.8179 - regression_loss: 0.7171 - classification_loss: 0.1008 - val_loss: 0.8779 - val_regression_loss: 0.7525 - val_classification_loss: 0.1177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8583\n",
      "mAP: 0.8583\n",
      "\n",
      "Epoch 00031: saving model to ./snapshots/resnet50_pascal_31.h5\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 586s 1s/step - loss: 0.8081 - regression_loss: 0.7071 - classification_loss: 0.1010 - val_loss: 0.8967 - val_regression_loss: 0.7657 - val_classification_loss: 0.1182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:21 Time:  0:00:21\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8576\n",
      "mAP: 0.8576\n",
      "\n",
      "Epoch 00032: saving model to ./snapshots/resnet50_pascal_32.h5\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 602s 1s/step - loss: 0.8143 - regression_loss: 0.7128 - classification_loss: 0.1015 - val_loss: 0.8893 - val_regression_loss: 0.7588 - val_classification_loss: 0.1175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8575\n",
      "mAP: 0.8575\n",
      "\n",
      "Epoch 00033: saving model to ./snapshots/resnet50_pascal_33.h5\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 575s 1s/step - loss: 0.8176 - regression_loss: 0.7175 - classification_loss: 0.1001 - val_loss: 0.8906 - val_regression_loss: 0.7608 - val_classification_loss: 0.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8581\n",
      "mAP: 0.8581\n",
      "\n",
      "Epoch 00034: saving model to ./snapshots/resnet50_pascal_34.h5\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 571s 1s/step - loss: 0.8162 - regression_loss: 0.7133 - classification_loss: 0.1030 - val_loss: 0.8840 - val_regression_loss: 0.7555 - val_classification_loss: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8574\n",
      "mAP: 0.8574\n",
      "\n",
      "Epoch 00035: saving model to ./snapshots/resnet50_pascal_35.h5\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 594s 1s/step - loss: 0.8046 - regression_loss: 0.7047 - classification_loss: 0.0998 - val_loss: 0.8989 - val_regression_loss: 0.7710 - val_classification_loss: 0.1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8576\n",
      "mAP: 0.8576\n",
      "\n",
      "Epoch 00036: saving model to ./snapshots/resnet50_pascal_36.h5\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 584s 1s/step - loss: 0.8084 - regression_loss: 0.7075 - classification_loss: 0.1009 - val_loss: 0.9017 - val_regression_loss: 0.7751 - val_classification_loss: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8574\n",
      "mAP: 0.8574\n",
      "\n",
      "Epoch 00037: saving model to ./snapshots/resnet50_pascal_37.h5\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 606s 1s/step - loss: 0.8141 - regression_loss: 0.7143 - classification_loss: 0.0998 - val_loss: 0.8884 - val_regression_loss: 0.7596 - val_classification_loss: 0.1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8576\n",
      "mAP: 0.8576\n",
      "\n",
      "Epoch 00038: saving model to ./snapshots/resnet50_pascal_38.h5\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 587s 1s/step - loss: 0.8047 - regression_loss: 0.7048 - classification_loss: 0.0999 - val_loss: 0.8877 - val_regression_loss: 0.7594 - val_classification_loss: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8575\n",
      "mAP: 0.8575\n",
      "\n",
      "Epoch 00039: saving model to ./snapshots/resnet50_pascal_39.h5\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 575s 1s/step - loss: 0.8003 - regression_loss: 0.7007 - classification_loss: 0.0996 - val_loss: 0.8891 - val_regression_loss: 0.7607 - val_classification_loss: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8575\n",
      "mAP: 0.8575\n",
      "\n",
      "Epoch 00040: saving model to ./snapshots/resnet50_pascal_40.h5\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 590s 1s/step - loss: 0.8059 - regression_loss: 0.7058 - classification_loss: 0.1000 - val_loss: 0.8888 - val_regression_loss: 0.7610 - val_classification_loss: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8575\n",
      "mAP: 0.8575\n",
      "\n",
      "Epoch 00041: saving model to ./snapshots/resnet50_pascal_41.h5\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 577s 1s/step - loss: 0.8166 - regression_loss: 0.7149 - classification_loss: 0.1017 - val_loss: 0.8896 - val_regression_loss: 0.7620 - val_classification_loss: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8575\n",
      "mAP: 0.8575\n",
      "\n",
      "Epoch 00042: saving model to ./snapshots/resnet50_pascal_42.h5\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 582s 1s/step - loss: 0.8180 - regression_loss: 0.7170 - classification_loss: 0.1010 - val_loss: 0.8896 - val_regression_loss: 0.7620 - val_classification_loss: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8575\n",
      "mAP: 0.8575\n",
      "\n",
      "Epoch 00043: saving model to ./snapshots/resnet50_pascal_43.h5\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 607s 1s/step - loss: 0.7948 - regression_loss: 0.6964 - classification_loss: 0.0984 - val_loss: 0.8896 - val_regression_loss: 0.7621 - val_classification_loss: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8575\n",
      "mAP: 0.8575\n",
      "\n",
      "Epoch 00044: saving model to ./snapshots/resnet50_pascal_44.h5\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 571s 1s/step - loss: 0.8140 - regression_loss: 0.7138 - classification_loss: 0.1002 - val_loss: 0.8897 - val_regression_loss: 0.7621 - val_classification_loss: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8575\n",
      "mAP: 0.8575\n",
      "\n",
      "Epoch 00045: saving model to ./snapshots/resnet50_pascal_45.h5\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 590s 1s/step - loss: 0.8088 - regression_loss: 0.7070 - classification_loss: 0.1018 - val_loss: 0.8897 - val_regression_loss: 0.7622 - val_classification_loss: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8575\n",
      "mAP: 0.8575\n",
      "\n",
      "Epoch 00046: saving model to ./snapshots/resnet50_pascal_46.h5\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 593s 1s/step - loss: 0.8081 - regression_loss: 0.7078 - classification_loss: 0.1003 - val_loss: 0.8897 - val_regression_loss: 0.7622 - val_classification_loss: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:21 Time:  0:00:21\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8575\n",
      "mAP: 0.8575\n",
      "\n",
      "Epoch 00047: saving model to ./snapshots/resnet50_pascal_47.h5\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 599s 1s/step - loss: 0.8122 - regression_loss: 0.7112 - classification_loss: 0.1010 - val_loss: 0.8897 - val_regression_loss: 0.7622 - val_classification_loss: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8575\n",
      "mAP: 0.8575\n",
      "\n",
      "Epoch 00048: saving model to ./snapshots/resnet50_pascal_48.h5\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 577s 1s/step - loss: 0.8192 - regression_loss: 0.7174 - classification_loss: 0.1018 - val_loss: 0.8897 - val_regression_loss: 0.7622 - val_classification_loss: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:20 Time:  0:00:20\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8575\n",
      "mAP: 0.8575\n",
      "\n",
      "Epoch 00049: saving model to ./snapshots/resnet50_pascal_49.h5\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 589s 1s/step - loss: 0.8071 - regression_loss: 0.7085 - classification_loss: 0.0986 - val_loss: 0.8897 - val_regression_loss: 0.7622 - val_classification_loss: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:21 Time:  0:00:21\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7612 instances of class pack with average precision: 0.8575\n",
      "mAP: 0.8575\n",
      "\n",
      "Epoch 00050: saving model to ./snapshots/resnet50_pascal_50.h5\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f29f01d18d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg = ['--gpu','1','--batch-size','1','--random-transform','--compute-val-loss','--freeze-backbone','--epochs','50','--steps','500','pascal','/ai/data/VOC2012']\n",
    "main(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
