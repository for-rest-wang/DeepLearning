{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from datetime import date\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "from augmentor.color import VisualEffect\n",
    "from augmentor.misc import MiscEffect\n",
    "from model import efficientdet\n",
    "from losses import smooth_l1, focal, smooth_l1_quad\n",
    "from efficientnet import BASE_WEIGHTS_PATH, WEIGHTS_HASHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(device=gpus[1], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedirs(path):\n",
    "    # Intended behavior: try to create the directory,\n",
    "    # pass if the directory exists already, fails otherwise.\n",
    "    # Meant for Python 2.7/3.n compatibility.\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session():\n",
    "    \"\"\"\n",
    "    Construct a modified tf session.\n",
    "    \"\"\"\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(training_model, prediction_model, validation_generator, args):\n",
    "    \"\"\"\n",
    "    Creates the callbacks to use during training.\n",
    "\n",
    "    Args\n",
    "        training_model: The model that is used for training.\n",
    "        prediction_model: The model that should be used for validation.\n",
    "        validation_generator: The generator for creating validation data.\n",
    "        args: parseargs args object.\n",
    "\n",
    "    Returns:\n",
    "        A list of callbacks used for training.\n",
    "    \"\"\"\n",
    "    callbacks = []\n",
    "\n",
    "    tensorboard_callback = None\n",
    "\n",
    "    if args.tensorboard_dir:\n",
    "        if tf.version.VERSION > '2.0.0':\n",
    "            file_writer = tf.summary.create_file_writer(args.tensorboard_dir)\n",
    "            file_writer.set_as_default()\n",
    "        tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "            log_dir=args.tensorboard_dir,\n",
    "            histogram_freq=0,\n",
    "            batch_size=args.batch_size,\n",
    "            write_graph=True,\n",
    "            write_grads=False,\n",
    "            write_images=False,\n",
    "            embeddings_freq=0,\n",
    "            embeddings_layer_names=None,\n",
    "            embeddings_metadata=None\n",
    "        )\n",
    "        callbacks.append(tensorboard_callback)\n",
    "\n",
    "    if args.evaluation and validation_generator:\n",
    "        if args.dataset_type == 'coco':\n",
    "            from eval.coco import Evaluate\n",
    "            # use prediction model for evaluation\n",
    "            evaluation = Evaluate(validation_generator, prediction_model, tensorboard=tensorboard_callback)\n",
    "        else:\n",
    "            from eval.pascal import Evaluate\n",
    "            evaluation = Evaluate(validation_generator, prediction_model, tensorboard=tensorboard_callback)\n",
    "        callbacks.append(evaluation)\n",
    "\n",
    "    # save the model\n",
    "    if args.snapshots:\n",
    "        # ensure directory created first; otherwise h5py will error after epoch.\n",
    "        makedirs(args.snapshot_path)\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "            os.path.join(\n",
    "                args.snapshot_path,\n",
    "                f'{args.dataset_type}_{{epoch:02d}}_{{loss:.4f}}_{{val_loss:.4f}}.h5' if args.compute_val_loss\n",
    "                else f'{args.dataset_type}_{{epoch:02d}}_{{loss:.4f}}.h5'\n",
    "            ),\n",
    "            verbose=1,\n",
    "            save_weights_only=True,\n",
    "            # save_best_only=True,\n",
    "            # monitor=\"mAP\",\n",
    "            # mode='max'\n",
    "        )\n",
    "        callbacks.append(checkpoint)\n",
    "\n",
    "    # callbacks.append(keras.callbacks.ReduceLROnPlateau(\n",
    "    #     monitor='loss',\n",
    "    #     factor=0.1,\n",
    "    #     patience=2,\n",
    "    #     verbose=1,\n",
    "    #     mode='auto',\n",
    "    #     min_delta=0.0001,\n",
    "    #     cooldown=0,\n",
    "    #     min_lr=0\n",
    "    # ))\n",
    "\n",
    "    return callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generators(args):\n",
    "    \"\"\"\n",
    "    Create generators for training and validation.\n",
    "\n",
    "    Args\n",
    "        args: parseargs object containing configuration for generators.\n",
    "        preprocess_image: Function that preprocesses an image for the network.\n",
    "    \"\"\"\n",
    "    common_args = {\n",
    "        'batch_size': args.batch_size,\n",
    "        'phi': args.phi,\n",
    "        'detect_text': args.detect_text,\n",
    "        'detect_quadrangle': args.detect_quadrangle\n",
    "    }\n",
    "\n",
    "    # create random transform generator for augmenting training data\n",
    "    if args.random_transform:\n",
    "        misc_effect = MiscEffect()\n",
    "        visual_effect = VisualEffect()\n",
    "    else:\n",
    "        misc_effect = None\n",
    "        visual_effect = None\n",
    "\n",
    "    if args.dataset_type == 'pascal':\n",
    "        from generators.pascal import PascalVocGenerator\n",
    "        train_generator = PascalVocGenerator(\n",
    "            args.pascal_path,\n",
    "            'train',\n",
    "            classes = {'pack':0},\n",
    "            skip_difficult=True,\n",
    "            misc_effect=misc_effect,\n",
    "            visual_effect=visual_effect,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        validation_generator = PascalVocGenerator(\n",
    "            args.pascal_path,\n",
    "            'val',\n",
    "            classes = {'pack':0},\n",
    "            skip_difficult=True,\n",
    "            shuffle_groups=False,\n",
    "            **common_args\n",
    "        )\n",
    "    elif args.dataset_type == 'csv':\n",
    "        from generators.csv_ import CSVGenerator\n",
    "        train_generator = CSVGenerator(\n",
    "            args.annotations_path,\n",
    "            args.classes_path,\n",
    "            misc_effect=misc_effect,\n",
    "            visual_effect=visual_effect,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        if args.val_annotations_path:\n",
    "            validation_generator = CSVGenerator(\n",
    "                args.val_annotations_path,\n",
    "                args.classes_path,\n",
    "                shuffle_groups=False,\n",
    "                **common_args\n",
    "            )\n",
    "        else:\n",
    "            validation_generator = None\n",
    "    elif args.dataset_type == 'coco':\n",
    "        # import here to prevent unnecessary dependency on cocoapi\n",
    "        from generators.coco import CocoGenerator\n",
    "        train_generator = CocoGenerator(\n",
    "            args.coco_path,\n",
    "            'train2017',\n",
    "            misc_effect=misc_effect,\n",
    "            visual_effect=visual_effect,\n",
    "            group_method='random',\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        validation_generator = CocoGenerator(\n",
    "            args.coco_path,\n",
    "            'val2017',\n",
    "            shuffle_groups=False,\n",
    "            **common_args\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('Invalid data type received: {}'.format(args.dataset_type))\n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_args(parsed_args):\n",
    "    \"\"\"\n",
    "    Function to check for inherent contradictions within parsed arguments.\n",
    "    For example, batch_size < num_gpus\n",
    "    Intended to raise errors prior to backend initialisation.\n",
    "\n",
    "    Args\n",
    "        parsed_args: parser.parse_args()\n",
    "\n",
    "    Returns\n",
    "        parsed_args\n",
    "    \"\"\"\n",
    "\n",
    "    if parsed_args.gpu and parsed_args.batch_size < len(parsed_args.gpu.split(',')):\n",
    "        raise ValueError(\n",
    "            \"Batch size ({}) must be equal to or higher than the number of GPUs ({})\".format(parsed_args.batch_size,\n",
    "                                                                                             len(parsed_args.gpu.split(\n",
    "                                                                                                 ','))))\n",
    "\n",
    "    return parsed_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args):\n",
    "    \"\"\"\n",
    "    Parse the arguments.\n",
    "    \"\"\"\n",
    "    today = str(date.today())\n",
    "    parser = argparse.ArgumentParser(description='Simple training script for training a RetinaNet network.')\n",
    "    subparsers = parser.add_subparsers(help='Arguments for specific dataset types.', dest='dataset_type')\n",
    "    subparsers.required = True\n",
    "\n",
    "    coco_parser = subparsers.add_parser('coco')\n",
    "    coco_parser.add_argument('coco_path', help='Path to dataset directory (ie. /tmp/COCO).')\n",
    "\n",
    "    pascal_parser = subparsers.add_parser('pascal')\n",
    "    pascal_parser.add_argument('pascal_path', help='Path to dataset directory (ie. /tmp/VOCdevkit).')\n",
    "\n",
    "    csv_parser = subparsers.add_parser('csv')\n",
    "    csv_parser.add_argument('annotations_path', help='Path to CSV file containing annotations for training.')\n",
    "    csv_parser.add_argument('classes_path', help='Path to a CSV file containing class label mapping.')\n",
    "    csv_parser.add_argument('--val-annotations-path',\n",
    "                            help='Path to CSV file containing annotations for validation (optional).')\n",
    "    parser.add_argument('--detect-quadrangle', help='If to detect quadrangle.', action='store_true', default=False)\n",
    "    parser.add_argument('--detect-text', help='If is text detection task.', action='store_true', default=False)\n",
    "\n",
    "    parser.add_argument('--snapshot', help='Resume training from a snapshot.')\n",
    "    parser.add_argument('--freeze-backbone', help='Freeze training of backbone layers.', action='store_true')\n",
    "    parser.add_argument('--freeze-bn', help='Freeze training of BatchNormalization layers.', action='store_true')\n",
    "    parser.add_argument('--weighted-bifpn', help='Use weighted BiFPN', action='store_true')\n",
    "\n",
    "    parser.add_argument('--batch-size', help='Size of the batches.', default=1, type=int)\n",
    "    parser.add_argument('--phi', help='Hyper parameter phi', default=0, type=int, choices=(0, 1, 2, 3, 4, 5, 6))\n",
    "    parser.add_argument('--gpu', help='Id of the GPU to use (as reported by nvidia-smi).')\n",
    "    parser.add_argument('--epochs', help='Number of epochs to train.', type=int, default=50)\n",
    "    parser.add_argument('--steps', help='Number of steps per epoch.', type=int, default=10000)\n",
    "    parser.add_argument('--snapshot-path',\n",
    "                        help='Path to store snapshots of models during training',\n",
    "                        default='checkpoints/{}'.format(today))\n",
    "    parser.add_argument('--tensorboard-dir', help='Log directory for Tensorboard output',\n",
    "                        default='logs/{}'.format(today))\n",
    "    parser.add_argument('--no-snapshots', help='Disable saving snapshots.', dest='snapshots', action='store_false')\n",
    "    parser.add_argument('--no-evaluation', help='Disable per epoch evaluation.', dest='evaluation',\n",
    "                        action='store_false')\n",
    "    parser.add_argument('--random-transform', help='Randomly transform image and annotations.', action='store_true')\n",
    "    parser.add_argument('--compute-val-loss', help='Compute validation loss during training', dest='compute_val_loss',\n",
    "                        action='store_true')\n",
    "\n",
    "    # Fit generator arguments\n",
    "    parser.add_argument('--multiprocessing', help='Use multiprocessing in fit_generator.', action='store_true')\n",
    "    parser.add_argument('--workers', help='Number of generator workers.', type=int, default=1)\n",
    "    parser.add_argument('--max-queue-size', help='Queue length for multiprocessing workers in fit_generator.', type=int,\n",
    "                        default=10)\n",
    "    print(vars(parser.parse_args(args)))\n",
    "    return check_args(parser.parse_args(args))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args=None):\n",
    "    # parse arguments\n",
    "    if args is None:\n",
    "        args = sys.argv[1:]\n",
    "    args = parse_args(args)\n",
    "\n",
    "    # create the generators\n",
    "    train_generator, validation_generator = create_generators(args)\n",
    "\n",
    "    num_classes = train_generator.num_classes()\n",
    "    num_anchors = train_generator.num_anchors\n",
    "\n",
    "    # optionally choose specific GPU\n",
    "    if args.gpu:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "\n",
    "    # K.set_session(get_session())\n",
    "\n",
    "    model, prediction_model = efficientdet(args.phi,\n",
    "                                           num_classes=num_classes,\n",
    "                                           num_anchors=num_anchors,\n",
    "                                           weighted_bifpn=args.weighted_bifpn,\n",
    "                                           freeze_bn=args.freeze_bn,\n",
    "                                           detect_quadrangle=args.detect_quadrangle\n",
    "                                           )\n",
    "    # load pretrained weights\n",
    "    if args.snapshot:\n",
    "        if args.snapshot == 'imagenet':\n",
    "            model_name = 'efficientnet-b{}'.format(args.phi)\n",
    "            file_name = '{}_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'.format(model_name)\n",
    "            file_hash = WEIGHTS_HASHES[model_name][1]\n",
    "            weights_path = keras.utils.get_file(file_name,\n",
    "                                                BASE_WEIGHTS_PATH + file_name,\n",
    "                                                cache_subdir='models',\n",
    "                                                file_hash=file_hash)\n",
    "            model.load_weights(weights_path, by_name=True)\n",
    "        else:\n",
    "            print('Loading model, this may take a second...')\n",
    "            model.load_weights(args.snapshot, by_name=True)\n",
    "\n",
    "    # freeze backbone layers\n",
    "    if args.freeze_backbone:\n",
    "        # 227, 329, 329, 374, 464, 566, 656\n",
    "        for i in range(1, [227, 329, 329, 374, 464, 566, 656][args.phi]):\n",
    "            model.layers[i].trainable = False\n",
    "\n",
    "    if args.gpu and len(args.gpu.split(',')) > 1:\n",
    "        model = keras.utils.multi_gpu_model(model, gpus=list(map(int, args.gpu.split(','))))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "        'regression': smooth_l1_quad() if args.detect_quadrangle else smooth_l1(),\n",
    "        'classification': focal()\n",
    "    }, )\n",
    "\n",
    "    # print(model.summary())\n",
    "\n",
    "    # create the callbacks\n",
    "    callbacks = create_callbacks(\n",
    "        model,\n",
    "        prediction_model,\n",
    "        validation_generator,\n",
    "        args,\n",
    "    )\n",
    "\n",
    "    if not args.compute_val_loss:\n",
    "        validation_generator = None\n",
    "    elif args.compute_val_loss and validation_generator is None:\n",
    "        raise ValueError('When you have no validation data, you should not specify --compute-val-loss.')\n",
    "\n",
    "    # start training\n",
    "    return model.fit(\n",
    "        x=train_generator,\n",
    "        steps_per_epoch=args.steps,\n",
    "        initial_epoch=0,\n",
    "        epochs=args.epochs,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        workers=args.workers,\n",
    "        use_multiprocessing=args.multiprocessing,\n",
    "        max_queue_size=args.max_queue_size,\n",
    "        validation_data=validation_generator\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_type': 'pascal', 'detect_quadrangle': False, 'detect_text': False, 'snapshot': 'imagenet', 'freeze_backbone': True, 'freeze_bn': False, 'weighted_bifpn': False, 'batch_size': 1, 'phi': 5, 'gpu': '1', 'epochs': 20, 'steps': 500, 'snapshot_path': 'checkpoints/2020-08-04', 'tensorboard_dir': 'logs/2020-08-04', 'snapshots': True, 'evaluation': True, 'random_transform': True, 'compute_val_loss': True, 'multiprocessing': False, 'workers': 1, 'max_queue_size': 10, 'pascal_path': '/ai/data/VOC2012'}\n",
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n",
      "Epoch 1/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5363 - classification_loss: 0.3367 - regression_loss: 0.1996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:46 Time:  0:00:46\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=9791.0, num_tp=109.0\n",
      "7612 instances of class pack with average precision: 0.0003\n",
      "mAP: 0.0003\n",
      "\n",
      "Epoch 00001: saving model to checkpoints/2020-08-04/pascal_01_0.5363_1.5162.h5\n",
      "500/500 [==============================] - 500s 1000ms/step - loss: 0.5363 - classification_loss: 0.3367 - regression_loss: 0.1996 - val_loss: 1.5162 - val_classification_loss: 1.0762 - val_regression_loss: 0.4399 - mAP: 3.2772e-04\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2618 - classification_loss: 0.1598 - regression_loss: 0.1020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:38 Time:  0:00:38\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=9789.0, num_tp=111.0\n",
      "7612 instances of class pack with average precision: 0.0003\n",
      "mAP: 0.0003\n",
      "\n",
      "Epoch 00002: saving model to checkpoints/2020-08-04/pascal_02_0.2618_1.5086.h5\n",
      "500/500 [==============================] - 480s 960ms/step - loss: 0.2618 - classification_loss: 0.1598 - regression_loss: 0.1020 - val_loss: 1.5086 - val_classification_loss: 1.0902 - val_regression_loss: 0.4184 - mAP: 2.6223e-04\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2225 - classification_loss: 0.1355 - regression_loss: 0.0871"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:38 Time:  0:00:38\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3380.0, num_tp=6520.0\n",
      "7612 instances of class pack with average precision: 0.8452\n",
      "mAP: 0.8452\n",
      "\n",
      "Epoch 00003: saving model to checkpoints/2020-08-04/pascal_03_0.2225_0.3804.h5\n",
      "500/500 [==============================] - 484s 967ms/step - loss: 0.2225 - classification_loss: 0.1355 - regression_loss: 0.0871 - val_loss: 0.3804 - val_classification_loss: 0.2500 - val_regression_loss: 0.1304 - mAP: 0.8452\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1997 - classification_loss: 0.1205 - regression_loss: 0.0791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:38 Time:  0:00:38\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3081.0, num_tp=6819.0\n",
      "7612 instances of class pack with average precision: 0.8840\n",
      "mAP: 0.8840\n",
      "\n",
      "Epoch 00004: saving model to checkpoints/2020-08-04/pascal_04_0.1997_0.2577.h5\n",
      "500/500 [==============================] - 486s 973ms/step - loss: 0.1997 - classification_loss: 0.1205 - regression_loss: 0.0791 - val_loss: 0.2577 - val_classification_loss: 0.1583 - val_regression_loss: 0.0994 - mAP: 0.8840\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1677 - classification_loss: 0.1007 - regression_loss: 0.0670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:38 Time:  0:00:38\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3063.0, num_tp=6837.0\n",
      "7612 instances of class pack with average precision: 0.8896\n",
      "mAP: 0.8896\n",
      "\n",
      "Epoch 00005: saving model to checkpoints/2020-08-04/pascal_05_0.1677_0.2143.h5\n",
      "500/500 [==============================] - 490s 980ms/step - loss: 0.1677 - classification_loss: 0.1007 - regression_loss: 0.0670 - val_loss: 0.2143 - val_classification_loss: 0.1344 - val_regression_loss: 0.0798 - mAP: 0.8896\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1651 - classification_loss: 0.0997 - regression_loss: 0.0655"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:37 Time:  0:00:37\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3046.0, num_tp=6854.0\n",
      "7612 instances of class pack with average precision: 0.8896\n",
      "mAP: 0.8896\n",
      "\n",
      "Epoch 00006: saving model to checkpoints/2020-08-04/pascal_06_0.1651_0.2407.h5\n",
      "500/500 [==============================] - 482s 964ms/step - loss: 0.1651 - classification_loss: 0.0997 - regression_loss: 0.0655 - val_loss: 0.2407 - val_classification_loss: 0.1553 - val_regression_loss: 0.0854 - mAP: 0.8896\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1552 - classification_loss: 0.0928 - regression_loss: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:37 Time:  0:00:37\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3068.0, num_tp=6832.0\n",
      "7612 instances of class pack with average precision: 0.8874\n",
      "mAP: 0.8874\n",
      "\n",
      "Epoch 00007: saving model to checkpoints/2020-08-04/pascal_07_0.1552_0.1959.h5\n",
      "500/500 [==============================] - 488s 977ms/step - loss: 0.1552 - classification_loss: 0.0928 - regression_loss: 0.0625 - val_loss: 0.1959 - val_classification_loss: 0.1269 - val_regression_loss: 0.0691 - mAP: 0.8874\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1445 - classification_loss: 0.0867 - regression_loss: 0.0578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:37 Time:  0:00:37\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3062.0, num_tp=6838.0\n",
      "7612 instances of class pack with average precision: 0.8904\n",
      "mAP: 0.8904\n",
      "\n",
      "Epoch 00008: saving model to checkpoints/2020-08-04/pascal_08_0.1445_0.2214.h5\n",
      "500/500 [==============================] - 489s 977ms/step - loss: 0.1445 - classification_loss: 0.0867 - regression_loss: 0.0578 - val_loss: 0.2214 - val_classification_loss: 0.1476 - val_regression_loss: 0.0738 - mAP: 0.8904\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1414 - classification_loss: 0.0851 - regression_loss: 0.0563"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:37 Time:  0:00:37\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3103.0, num_tp=6797.0\n",
      "7612 instances of class pack with average precision: 0.8843\n",
      "mAP: 0.8843\n",
      "\n",
      "Epoch 00009: saving model to checkpoints/2020-08-04/pascal_09_0.1414_0.2113.h5\n",
      "500/500 [==============================] - 481s 963ms/step - loss: 0.1414 - classification_loss: 0.0851 - regression_loss: 0.0563 - val_loss: 0.2113 - val_classification_loss: 0.1339 - val_regression_loss: 0.0774 - mAP: 0.8843\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1335 - classification_loss: 0.0798 - regression_loss: 0.0537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:38 Time:  0:00:38\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3056.0, num_tp=6844.0\n",
      "7612 instances of class pack with average precision: 0.8908\n",
      "mAP: 0.8908\n",
      "\n",
      "Epoch 00010: saving model to checkpoints/2020-08-04/pascal_10_0.1335_0.1892.h5\n",
      "500/500 [==============================] - 490s 980ms/step - loss: 0.1335 - classification_loss: 0.0798 - regression_loss: 0.0537 - val_loss: 0.1892 - val_classification_loss: 0.1224 - val_regression_loss: 0.0668 - mAP: 0.8908\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1312 - classification_loss: 0.0792 - regression_loss: 0.0520"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:37 Time:  0:00:37\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3042.0, num_tp=6858.0\n",
      "7612 instances of class pack with average precision: 0.8933\n",
      "mAP: 0.8933\n",
      "\n",
      "Epoch 00011: saving model to checkpoints/2020-08-04/pascal_11_0.1312_0.1705.h5\n",
      "500/500 [==============================] - 486s 972ms/step - loss: 0.1312 - classification_loss: 0.0792 - regression_loss: 0.0520 - val_loss: 0.1705 - val_classification_loss: 0.1114 - val_regression_loss: 0.0591 - mAP: 0.8933\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1253 - classification_loss: 0.0744 - regression_loss: 0.0509"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:37 Time:  0:00:37\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3035.0, num_tp=6865.0\n",
      "7612 instances of class pack with average precision: 0.8944\n",
      "mAP: 0.8944\n",
      "\n",
      "Epoch 00012: saving model to checkpoints/2020-08-04/pascal_12_0.1253_0.1971.h5\n",
      "500/500 [==============================] - 481s 963ms/step - loss: 0.1253 - classification_loss: 0.0744 - regression_loss: 0.0509 - val_loss: 0.1971 - val_classification_loss: 0.1274 - val_regression_loss: 0.0697 - mAP: 0.8944\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1190 - classification_loss: 0.0701 - regression_loss: 0.0488"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:37 Time:  0:00:37\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3006.0, num_tp=6894.0\n",
      "7612 instances of class pack with average precision: 0.8990\n",
      "mAP: 0.8990\n",
      "\n",
      "Epoch 00013: saving model to checkpoints/2020-08-04/pascal_13_0.1190_0.1902.h5\n",
      "500/500 [==============================] - 485s 970ms/step - loss: 0.1190 - classification_loss: 0.0701 - regression_loss: 0.0488 - val_loss: 0.1902 - val_classification_loss: 0.1326 - val_regression_loss: 0.0577 - mAP: 0.8990\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1141 - classification_loss: 0.0668 - regression_loss: 0.0473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:38 Time:  0:00:38\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3010.0, num_tp=6890.0\n",
      "7612 instances of class pack with average precision: 0.8980\n",
      "mAP: 0.8980\n",
      "\n",
      "Epoch 00014: saving model to checkpoints/2020-08-04/pascal_14_0.1141_0.1893.h5\n",
      "500/500 [==============================] - 485s 970ms/step - loss: 0.1141 - classification_loss: 0.0668 - regression_loss: 0.0473 - val_loss: 0.1893 - val_classification_loss: 0.1233 - val_regression_loss: 0.0660 - mAP: 0.8980\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1152 - classification_loss: 0.0681 - regression_loss: 0.0472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:38 Time:  0:00:38\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3009.0, num_tp=6891.0\n",
      "7612 instances of class pack with average precision: 0.8977\n",
      "mAP: 0.8977\n",
      "\n",
      "Epoch 00015: saving model to checkpoints/2020-08-04/pascal_15_0.1152_0.1799.h5\n",
      "500/500 [==============================] - 483s 966ms/step - loss: 0.1152 - classification_loss: 0.0681 - regression_loss: 0.0472 - val_loss: 0.1799 - val_classification_loss: 0.1228 - val_regression_loss: 0.0571 - mAP: 0.8977\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1084 - classification_loss: 0.0632 - regression_loss: 0.0451"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:38 Time:  0:00:38\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3011.0, num_tp=6889.0\n",
      "7612 instances of class pack with average precision: 0.8983\n",
      "mAP: 0.8983\n",
      "\n",
      "Epoch 00016: saving model to checkpoints/2020-08-04/pascal_16_0.1084_0.1674.h5\n",
      "500/500 [==============================] - 482s 965ms/step - loss: 0.1084 - classification_loss: 0.0632 - regression_loss: 0.0451 - val_loss: 0.1674 - val_classification_loss: 0.1077 - val_regression_loss: 0.0597 - mAP: 0.8983\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1099 - classification_loss: 0.0645 - regression_loss: 0.0454"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:37 Time:  0:00:37\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3022.0, num_tp=6878.0\n",
      "7612 instances of class pack with average precision: 0.8961\n",
      "mAP: 0.8961\n",
      "\n",
      "Epoch 00017: saving model to checkpoints/2020-08-04/pascal_17_0.1099_0.1729.h5\n",
      "500/500 [==============================] - 483s 965ms/step - loss: 0.1099 - classification_loss: 0.0645 - regression_loss: 0.0454 - val_loss: 0.1729 - val_classification_loss: 0.1123 - val_regression_loss: 0.0606 - mAP: 0.8961\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1062 - classification_loss: 0.0626 - regression_loss: 0.0436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:37 Time:  0:00:37\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=2999.0, num_tp=6901.0\n",
      "7612 instances of class pack with average precision: 0.9003\n",
      "mAP: 0.9003\n",
      "\n",
      "Epoch 00018: saving model to checkpoints/2020-08-04/pascal_18_0.1062_0.1540.h5\n",
      "500/500 [==============================] - 488s 975ms/step - loss: 0.1062 - classification_loss: 0.0626 - regression_loss: 0.0436 - val_loss: 0.1540 - val_classification_loss: 0.0958 - val_regression_loss: 0.0582 - mAP: 0.9003\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1007 - classification_loss: 0.0576 - regression_loss: 0.0430"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:37 Time:  0:00:37\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=3059.0, num_tp=6841.0\n",
      "7612 instances of class pack with average precision: 0.8893\n",
      "mAP: 0.8893\n",
      "\n",
      "Epoch 00019: saving model to checkpoints/2020-08-04/pascal_19_0.1007_0.1659.h5\n",
      "500/500 [==============================] - 485s 970ms/step - loss: 0.1007 - classification_loss: 0.0576 - regression_loss: 0.0430 - val_loss: 0.1659 - val_classification_loss: 0.1051 - val_regression_loss: 0.0608 - mAP: 0.8893\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0928 - classification_loss: 0.0529 - regression_loss: 0.0400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running network: 100% (99 of 99) |#######| Elapsed Time: 0:00:37 Time:  0:00:37\n",
      "Parsing annotations: 100% (99 of 99) |###| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fp=2998.0, num_tp=6902.0\n",
      "7612 instances of class pack with average precision: 0.9003\n",
      "mAP: 0.9003\n",
      "\n",
      "Epoch 00020: saving model to checkpoints/2020-08-04/pascal_20_0.0928_0.1898.h5\n",
      "500/500 [==============================] - 480s 960ms/step - loss: 0.0928 - classification_loss: 0.0529 - regression_loss: 0.0400 - val_loss: 0.1898 - val_classification_loss: 0.1301 - val_regression_loss: 0.0596 - mAP: 0.9003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdf8c25eba8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = ['--snapshot','imagenet', '--phi','5','--gpu','1','--random-transform','--compute-val-loss','--freeze-backbone','--epochs','20','--steps','500','pascal','/ai/data/VOC2012']\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
